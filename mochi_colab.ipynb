{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48374691",
   "metadata": {},
   "source": [
    "# üé¨ Mochi Video Generator - Colab Edition\n",
    "\n",
    "Generate videos using Genmo's Mochi model on Google Colab.\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab Pro/Pro+ recommended (for A100/V100 GPU with 40GB+ VRAM)\n",
    "- Free Colab T4 (15GB) may work with aggressive memory optimization\n",
    "\n",
    "‚ö†Ô∏è **First, set your runtime to GPU:** Runtime ‚Üí Change runtime type ‚Üí GPU (A100 recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfdb7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q diffusers transformers accelerate sentencepiece protobuf gradio hf_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df94ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Enable fast downloads\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "from diffusers import MochiPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "\n",
    "# Check GPU\n",
    "print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337813b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Mochi pipeline\n",
    "print(\"üì¶ Loading Mochi pipeline (this will download ~46GB on first run)...\")\n",
    "\n",
    "pipe = MochiPipeline.from_pretrained(\n",
    "    \"genmo/mochi-1-preview\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    variant=\"bf16\",\n",
    ")\n",
    "\n",
    "# Memory optimization based on available VRAM\n",
    "vram_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "\n",
    "if vram_gb >= 40:  # A100\n",
    "    pipe = pipe.to(\"cuda\")\n",
    "    print(\"‚úÖ Full GPU mode (A100)\")\n",
    "elif vram_gb >= 24:  # L4/A10G\n",
    "    pipe = pipe.to(\"cuda\")\n",
    "    pipe.enable_vae_tiling()\n",
    "    print(\"‚úÖ GPU mode with VAE tiling\")\n",
    "else:  # T4 (15GB)\n",
    "    pipe.enable_model_cpu_offload()\n",
    "    pipe.enable_vae_tiling()\n",
    "    pipe.enable_vae_slicing()\n",
    "    print(\"‚úÖ CPU offload mode (lower VRAM GPU)\")\n",
    "\n",
    "print(\"üé¨ Ready to generate videos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00289f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a video\n",
    "prompt = \"A horse galloping through a Tamil village, cinematic lighting, natural motion\"\n",
    "\n",
    "print(f\"üé¨ Generating video for: {prompt}\")\n",
    "print(\"‚è≥ This may take 2-10 minutes depending on GPU...\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    frames = pipe(\n",
    "        prompt,\n",
    "        num_inference_steps=28,\n",
    "        guidance_scale=3.5,\n",
    "    ).frames[0]\n",
    "\n",
    "# Save video\n",
    "video_path = export_to_video(frames, \"mochi_output.mp4\", fps=30)\n",
    "print(f\"‚úÖ Video saved to: {video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the video in Colab\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "with open(\"mochi_output.mp4\", \"rb\") as f:\n",
    "    video_data = b64encode(f.read()).decode()\n",
    "\n",
    "HTML(f'''\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"data:video/mp4;base64,{video_data}\" type=\"video/mp4\">\n",
    "</video>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf120591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the video\n",
    "from google.colab import files\n",
    "files.download(\"mochi_output.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13eafb",
   "metadata": {},
   "source": [
    "## üé® Interactive Mode (Optional)\n",
    "Run the cell below to launch a Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fbff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def generate_video(prompt, steps=28, guidance=3.5):\n",
    "    with torch.inference_mode():\n",
    "        frames = pipe(prompt, num_inference_steps=int(steps), guidance_scale=guidance).frames[0]\n",
    "    return export_to_video(frames, fps=30)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=generate_video,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Prompt\", placeholder=\"Describe your video...\"),\n",
    "        gr.Slider(10, 50, value=28, step=1, label=\"Inference Steps\"),\n",
    "        gr.Slider(1.0, 10.0, value=3.5, step=0.5, label=\"Guidance Scale\"),\n",
    "    ],\n",
    "    outputs=gr.Video(label=\"Generated Video\"),\n",
    "    title=\"üé¨ Mochi Video Generator\",\n",
    ")\n",
    "\n",
    "demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
